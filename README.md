# üß† Tarea 3: Sistema Distribuido de An√°lisis de Tr√°fico

Este proyecto implementa un sistema distribuido de extremo a extremo que recolecta, almacena, procesa y visualiza eventos de tr√°fico de la Regi√≥n Metropolitana. El sistema utiliza **Python** para la recolecci√≥n, **MongoDB** como base de datos primaria, **Apache Pig** para el procesamiento distribuido de datos y el **Stack El√°stico (Elasticsearch y Kibana)** para la visualizaci√≥n interactiva de m√©tricas y an√°lisis.

El objetivo final es proporcionar una herramienta que permita a tomadores de decisiones, como la Unidad de Control de Tr√°nsito, explorar patrones de tr√°fico de manera din√°mica y eficiente.

---

## üèóÔ∏è Arquitectura del Sistema

El flujo de datos sigue el siguiente pipeline:

1. **Scraper (Python)**: Recolecta eventos de tr√°fico (simulados, inspirados en Waze).
2. **Data Storage (MongoDB)**: Almacena los eventos en bruto.
3. **Procesamiento (Apache Pig)**: Procesa los datos para limpiar, filtrar y agregar m√©tricas clave (incidentes por comuna, tipo y fecha).
4. **Indexaci√≥n (Elasticsearch)**: Un exportador en Python toma los datos procesados por Pig y los indexa en Elasticsearch, prepar√°ndolos para b√∫squedas y visualizaciones r√°pidas.
5. **Visualizaci√≥n (Kibana)**: Kibana se conecta a Elasticsearch para mostrar los datos en un dashboard interactivo con gr√°ficos, mapas y tablas.

---

## üöÄ Instrucciones de Ejecuci√≥n

### 1. Prerrequisitos

* Tener instalado **Docker** y **Docker Compose**.

### 2. Clonar el Repositorio

```bash
git clone https://github.com/Kevin-css/tarea2_sd.git 
cd tarea2_sd

### 3. Ejecutar el Sistema Completo

```bash
docker-compose up --build
```

Este comando levantar√° cuatro servicios orquestados:

- **mongodb**: La base de datos para los datos en bruto.
- **elasticsearch**: El motor de b√∫squeda y anal√≠tica que almacena los datos procesados.
- **kibana**: La plataforma de visualizaci√≥n.
- **app**: El contenedor de Python que ejecuta el pipeline:
  - Genera y guarda los eventos en MongoDB.
  - Ejecuta el script de Apache Pig para procesar los datos.
  - Ejecuta el script `exportador_elastic.py` para enviar los resultados de Pig a Elasticsearch.
  - Genera logs de rendimiento del scraper y del cach√©, y los env√≠a a Elasticsearch.

### 4. Acceder a Kibana

Una vez que los contenedores est√©n corriendo, abre tu navegador y ve a:

```bash
http://localhost:5601
```

Dentro de Kibana, podr√°s crear las visualizaciones y el dashboard para explorar los datos del tr√°fico.

üìÅ **Archivos Clave del Proyecto**

```
Tarea_3_SD/
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquesta todos los servicios
‚îú‚îÄ‚îÄ Dockerfile             # Configura el contenedor de la aplicaci√≥n Python
‚îú‚îÄ‚îÄ exportador_elastic.py  # Env√≠a datos de CSV a Elasticsearch
‚îú‚îÄ‚îÄ procesar_eventos.pig   # Script de Pig para el an√°lisis de datos
‚îú‚îÄ‚îÄ main.py                # Punto de entrada que ejecuta el pipeline
‚îú‚îÄ‚îÄ config.py              # Par√°metros de configuraci√≥n del sistema
‚îú‚îÄ‚îÄ generador_eventos.py   # Simula los eventos de tr√°fico
‚îú‚îÄ‚îÄ cache.py               # L√≥gica del sistema de cach√©
‚îî‚îÄ‚îÄ ... otros archivos del sistema
```

üìä **Resultados y An√°lisis**

A diferencia de las etapas anteriores, el resultado final de este proyecto no son gr√°ficos est√°ticos, sino un dashboard interactivo en Kibana. Esta plataforma permite un an√°lisis mucho m√°s profundo y din√°mico de los datos.

**Funcionalidades del Dashboard:**

- **Visualizaci√≥n Integrada**: El panel de control unifica m√©tricas de rendimiento del sistema (logs del scraper y cach√©) con los datos de negocio (incidentes de tr√°fico).
- **An√°lisis Multidimensional**: Se pueden explorar los datos de tr√°fico clasificados por:
  - **Geograf√≠a**: Gr√°fico de barras con el total de incidentes por comuna.
  - **Tipolog√≠a**: Gr√°fico de torta que desglosa los incidentes por su tipo (choque, congesti√≥n, etc.).
  - **Temporalidad**: Gr√°fico de l√≠neas que muestra la evoluci√≥n de los incidentes a lo largo del tiempo.
- **Interactividad y Filtrado Din√°mico**: La principal ventaja del sistema es la capacidad de filtrar los datos en tiempo real. Al hacer clic en una comuna o un tipo de incidente en un gr√°fico, todos los dem√°s gr√°ficos del dashboard se actualizan autom√°ticamente para reflejar la selecci√≥n, permitiendo descubrir patrones complejos de manera intuitiva.

Este sistema distribuido completo demuestra c√≥mo transformar datos en bruto en conocimiento accionable, proveyendo una herramienta visual poderosa para la toma de decisiones informadas en la gesti√≥n del tr√°fico urbano.

üõ†Ô∏è **Tecnolog√≠as Utilizadas**

- **Lenguaje**: Python 3.10+
- **Contenerizaci√≥n**: Docker y Docker Compose
- **Base de Datos Primaria**: MongoDB
- **Procesamiento de Datos**: Apache Pig
- **B√∫squeda y Anal√≠tica**: Elasticsearch
- **Visualizaci√≥n**: Kibana
- **Librer√≠as Python**: elasticsearch, pymongo, pandas, etc.

üìú **Licencia**

Este proyecto es parte de la entrega del curso "Sistemas Distribuidos - Universidad Diego Portales (2025)".
